{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.plot(history.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Puan</th>\n",
       "      <th>Yorum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Çak iyi fiyata çok iyi ürün Tam zamanında kusu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Mükemmel Ürün siparişi verdim ve 24 saatten kı...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>beğenmedim ses seviyesi beklediğimden düşük bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Klavye Bildiğiniz klavye klavye olduğu için öv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Ucuz çok iyi değil ama idare eder TV nin plast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79547</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Kaliteli Urun Hizli Kargo Pazar gunu siparis v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79548</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Harika bir ürün Umduğumdan çok daha iyi görünt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79549</th>\n",
       "      <td>1.0</td>\n",
       "      <td>sağlam ve güzel paketleme sağlam ve güzel pake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79550</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Kargo rezil Mağaza ilgili değil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79551</th>\n",
       "      <td>1.0</td>\n",
       "      <td>süper şık ve kaliteli piyasada ki muadil ürünl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79552 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Puan                                              Yorum\n",
       "0       1.0  Çak iyi fiyata çok iyi ürün Tam zamanında kusu...\n",
       "1       1.0  Mükemmel Ürün siparişi verdim ve 24 saatten kı...\n",
       "2       0.0  beğenmedim ses seviyesi beklediğimden düşük bu...\n",
       "3       0.0  Klavye Bildiğiniz klavye klavye olduğu için öv...\n",
       "4       0.0  Ucuz çok iyi değil ama idare eder TV nin plast...\n",
       "...     ...                                                ...\n",
       "79547   0.0  Kaliteli Urun Hizli Kargo Pazar gunu siparis v...\n",
       "79548   1.0  Harika bir ürün Umduğumdan çok daha iyi görünt...\n",
       "79549   1.0  sağlam ve güzel paketleme sağlam ve güzel pake...\n",
       "79550   0.0                    Kargo rezil Mağaza ilgili değil\n",
       "79551   1.0  süper şık ve kaliteli piyasada ki muadil ürünl...\n",
       "\n",
       "[79552 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('./yorumlar.csv')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_ds = tf.data.experimental.CsvDataset(\n",
    "    './yorumlar.csv',\n",
    "    [tf.string, tf.string],\n",
    "    compression_type=None,\n",
    "    buffer_size=None,\n",
    "    header=True,\n",
    "    field_delim=',',\n",
    "    use_quote_delim=True,\n",
    "    na_value='',\n",
    "    select_cols=None,\n",
    "    exclude_cols=None\n",
    ")\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "train_dataset = raw_train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = raw_train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts:  [1. 0. 1.]\n",
      "\n",
      "labels:  [b'Webdenal Say\\xc4\\xb1n M\\xc3\\xbc\\xc5\\x9fterimiz Taksit bilgileri \\xc3\\xbcr\\xc3\\xbcn sayfas\\xc4\\xb1n\\xc4\\xb1n alt\\xc4\\xb1nda yer almaktad\\xc4\\xb1r Sayg\\xc4\\xb1lar\\xc4\\xb1m\\xc4\\xb1zla'\n",
      " b'\\xc3\\x9cr\\xc3\\xbcn gelmedi \\xc3\\x9cr\\xc3\\xbcn gelmedi \\xc3\\xbcr\\xc3\\xbcn elime ula\\xc5\\x9fmad\\xc4\\xb1 birde yorum isteniyor'\n",
      " b'hitachi Hitachi ht 49 1700 ud modelini ald\\xc4\\xb1m g\\xc3\\xb6r\\xc3\\xbcnt\\xc3\\xbc kalitesi g\\xc3\\xbczel ses klasik Vestel sesi yani idare eder ekran\\xc4\\xb1n tam kar\\xc5\\x9f\\xc4\\xb1s\\xc4\\xb1nda durursan\\xc4\\xb1z g\\xc3\\xb6r\\xc3\\xbcnt\\xc3\\xbc daha net canl\\xc4\\xb1 ancak hafif yandan bak\\xc4\\xb1nca g\\xc3\\xb6r\\xc3\\xbcnt\\xc3\\xbc bulan\\xc4\\xb1k oluyor yani 178 derece yandan felan net g\\xc3\\xb6r\\xc3\\xbcnt\\xc3\\xbc almak biraz hayal']\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "  print('texts: ', example.numpy()[:3])\n",
    "  print()\n",
    "  print('labels: ', label.numpy()[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "\n",
    "data = dataframe[\"Yorum\"].values.tolist()\n",
    "encoder.adapt(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.data.experimental.CsvDataset(\n",
    "    './yorumlar.csv',\n",
    "    [tf.string, tf.string],\n",
    "    compression_type=None,\n",
    "    buffer_size=None,\n",
    "    header=True,\n",
    "    field_delim=',',\n",
    "    use_quote_delim=True,\n",
    "    na_value='',\n",
    "    select_cols=None,\n",
    "    exclude_cols=None\n",
    ")\n",
    "\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.data.experimental.CsvDataset(\n",
    "    './yorumlar.csv',\n",
    "    [tf.string, tf.string],\n",
    "    compression_type=None,\n",
    "    buffer_size=None,\n",
    "    header=True,\n",
    "    field_delim=',',\n",
    "    use_quote_delim=True,\n",
    "    na_value='',\n",
    "    select_cols=None,\n",
    "    exclude_cols=None\n",
    ")\n",
    "\n",
    "test_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "b'\\xc3\\x87ak iyi fiyata \\xc3\\xa7ok iyi \\xc3\\xbcr\\xc3\\xbcn Tam zaman\\xc4\\xb1nda kusursuz geldi servis randevusu online al\\xc4\\xb1nabiliyor ve ertesi g\\xc3\\xbcn kurulumu yap\\xc4\\xb1ld\\xc4\\xb1 te\\xc5\\x9fekk\\xc3\\xbcrler'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-08 21:56:21.688038: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "    print(text_batch.numpy())\n",
    "    print(label_batch.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: 1.0\n",
      "Label : b'\\xc3\\x87ak iyi fiyata \\xc3\\xa7ok iyi \\xc3\\xbcr\\xc3\\xbcn Tam zaman\\xc4\\xb1nda kusursuz geldi servis randevusu online al\\xc4\\xb1nabiliyor ve ertesi g\\xc3\\xbcn kurulumu yap\\xc4\\xb1ld\\xc4\\xb1 te\\xc5\\x9fekk\\xc3\\xbcrler' (b'\\xc3\\x87ak iyi fiyata \\xc3\\xa7ok iyi \\xc3\\xbcr\\xc3\\xbcn Tam zaman\\xc4\\xb1nda kusursuz geldi servis randevusu online al\\xc4\\xb1nabiliyor ve ertesi g\\xc3\\xbcn kurulumu yap\\xc4\\xb1ld\\xc4\\xb1 te\\xc5\\x9fekk\\xc3\\xbcrler')\n",
      "Review: 1.0\n",
      "Label : b'\\xc3\\x87ak iyi fiyata \\xc3\\xa7ok iyi \\xc3\\xbcr\\xc3\\xbcn Tam zaman\\xc4\\xb1nda kusursuz geldi servis randevusu online al\\xc4\\xb1nabiliyor ve ertesi g\\xc3\\xbcn kurulumu yap\\xc4\\xb1ld\\xc4\\xb1 te\\xc5\\x9fekk\\xc3\\xbcrler' (b'\\xc3\\x87ak iyi fiyata \\xc3\\xa7ok iyi \\xc3\\xbcr\\xc3\\xbcn Tam zaman\\xc4\\xb1nda kusursuz geldi servis randevusu online al\\xc4\\xb1nabiliyor ve ertesi g\\xc3\\xbcn kurulumu yap\\xc4\\xb1ld\\xc4\\xb1 te\\xc5\\x9fekk\\xc3\\xbcrler')\n",
      "Review: 1.0\n",
      "Label : b'\\xc3\\x87ak iyi fiyata \\xc3\\xa7ok iyi \\xc3\\xbcr\\xc3\\xbcn Tam zaman\\xc4\\xb1nda kusursuz geldi servis randevusu online al\\xc4\\xb1nabiliyor ve ertesi g\\xc3\\xbcn kurulumu yap\\xc4\\xb1ld\\xc4\\xb1 te\\xc5\\x9fekk\\xc3\\xbcrler' (b'\\xc3\\x87ak iyi fiyata \\xc3\\xa7ok iyi \\xc3\\xbcr\\xc3\\xbcn Tam zaman\\xc4\\xb1nda kusursuz geldi servis randevusu online al\\xc4\\xb1nabiliyor ve ertesi g\\xc3\\xbcn kurulumu yap\\xc4\\xb1ld\\xc4\\xb1 te\\xc5\\x9fekk\\xc3\\xbcrler')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-08 21:56:29.571690: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "  for i in range(3):\n",
    "    print(f'Review: {text_batch.numpy()}')\n",
    "    label = label_batch.numpy()\n",
    "    print(f'Label : {label} ({label})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'bir', 've', 'çok', 'ürün', 'bu', 'iyi', 'güzel',\n",
       "       'ama', 'için', 'daha', 'tavsiye', 'yıldız', 'yok', 'Ürün',\n",
       "       'ederim', 'da', 'gayet', 'gibi'], dtype='<U13')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "print([layer.supports_masking for layer in model.layers])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "[0.04080091]\n"
     ]
    }
   ],
   "source": [
    "sample_text = ('The movie was cool. The animation and the graphics '\n",
    "               'were out of this world. I would recommend this movie.')\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 134ms/step\n",
      "[0.04080091]\n"
     ]
    }
   ],
   "source": [
    "padding = \"the \" * 2000\n",
    "predictions = model.predict(np.array([sample_text, padding]))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/ma/Library/Python/3.9/lib/python/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/ma/Library/Python/3.9/lib/python/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/ma/Library/Python/3.9/lib/python/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/ma/Library/Python/3.9/lib/python/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/ma/Library/Python/3.9/lib/python/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/ma/Library/Python/3.9/lib/python/site-packages/keras/engine/input_spec.py\", line 232, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_2' (type Sequential).\n    \n    Input 0 of layer \"bidirectional_2\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 64)\n    \n    Call arguments received by layer 'sequential_2' (type Sequential):\n      • inputs=tf.Tensor(shape=(), dtype=string)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(raw_train_ds, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m      2\u001b[0m                     validation_data\u001b[39m=\u001b[39;49mtest_dataset,\n\u001b[1;32m      3\u001b[0m                     validation_steps\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/c5/chkn60592xq0kw5wlbds5bw80000gn/T/__autograph_generated_file6kezeq6e.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/ma/Library/Python/3.9/lib/python/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/ma/Library/Python/3.9/lib/python/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/ma/Library/Python/3.9/lib/python/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/ma/Library/Python/3.9/lib/python/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/ma/Library/Python/3.9/lib/python/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/ma/Library/Python/3.9/lib/python/site-packages/keras/engine/input_spec.py\", line 232, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_2' (type Sequential).\n    \n    Input 0 of layer \"bidirectional_2\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 64)\n    \n    Call arguments received by layer 'sequential_2' (type Sequential):\n      • inputs=tf.Tensor(shape=(), dtype=string)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(raw_train_ds, epochs=10,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
